"use client";
import { useState, useEffect, useRef, useCallback } from "react";

export default function AssistantVocal({ etapes = [], changeEtape }) {
    // compatibilit√© et interface
    const [supporte, setSupporte] = useState(false); // supporte les APIs vocales ou non
    const [showFallback, setShowFallback] = useState(false); // affiche interface de secours si supporte pas

    // √©tats de l'assistant
    const [ecoute, setEcoute] = useState(false);
    const [active, setActive] = useState(false);
    const [isProcessing, setIsProcessing] = useState(false);
    const [isReadingStep, setIsReadingStep] = useState(false);

    // navigation et feedback
    const [etapeActuelle, setEtapeActuelle] = useState(0);
    const [lastCommand, setLastCommand] = useState(""); // pour le tooltip

    // refs pour √©viter les probl√®mes de closure dans les callbacks
    const recognitionRef = useRef(null);
    const utteranceRef = useRef(null);
    const restartTimeoutRef = useRef(null); // pour red√©marrage automatique
    const speechQueueRef = useRef(false); // pour √©viter les synth√®ses vocales multiples
    const etapeActuelleRef = useRef(0);

    // seuil min. pour la confiance vocale
    const CONFIDENCE_THRESHOLD = 0.7;

    // gestion vocale
    const gererVocal = useCallback((action, params = {}) => {
        const { texte, isStep = false, etapeIndex } = params;

        switch (action) {
            case 'parler':
                // √©viter les synth√®ses multiples simultan√©es
                if (speechQueueRef.current) {
                    console.log('Synth√®se d√©j√† en cours, commande ignor√©e');
                    return;
                }
                // synth√®se en cours
                speechQueueRef.current = true;

                // arr√™ter toute synth√®se pr√©c√©dente pour √©viter les conflits
                window.speechSynthesis.cancel();
                if (utteranceRef.current) utteranceRef.current = null;

                // configurer et lancer la synth√®se
                const speak = () => {
                    const utterance = new SpeechSynthesisUtterance(texte);

                    utterance.lang = 'fr-FR';
                    utterance.rate = 0.8;
                    utterance.pitch = 1.0;
                    utterance.volume = 1.0;

                    // imposer voix fr
                    const voices = window.speechSynthesis.getVoices();

                    // voix Am√©lie safari
                    let selectedVoice = voices.find(voice => voice.name === 'Am√©lie');
                    if (!selectedVoice) {
                        selectedVoice = voices.find(voice => voice.name.includes('Google fran√ßais'));
                    }
                    // 1ere voix fr disponible ou voix par d√©faut
                    if (!selectedVoice) {
                        selectedVoice = voices.find(voice => voice.lang.startsWith('fr')) || voices[0];
                    }

                    utterance.voice = selectedVoice;

                    utterance.onstart = () => {
                        setIsProcessing(true);
                        if (isStep) setIsReadingStep(true);
                    };

                    // r√©initialiser tous les √©tats
                    utterance.onend = () => {
                        setIsProcessing(false);
                        speechQueueRef.current = false;
                        utteranceRef.current = null;
                        if (isStep) setIsReadingStep(false);
                    };

                    utterance.onerror = (event) => {
                        console.error('Erreur lors de la synth√®se vocale:', event.error);
                        // r√©initialiser en cas d'erreur
                        setIsProcessing(false);
                        speechQueueRef.current = false;
                        utteranceRef.current = null;
                        if (isStep) setIsReadingStep(false);
                    };

                    // sauvegarder la ref et lancer la synth√®se
                    utteranceRef.current = utterance;
                    window.speechSynthesis.speak(utterance);
                };

                // code g√©n√©r√© par Claude.ai
                // g√©rer le cas o√π les voix sont pas encore charg√©es
                if (window.speechSynthesis.getVoices().length === 0) {
                    // Attendre le chargement des voix
                    window.speechSynthesis.onvoiceschanged = () => {
                        window.speechSynthesis.onvoiceschanged = null; // Nettoyer le listener
                        speak();
                    };
                    // Fallback en cas de probl√®me avec onvoiceschanged
                    setTimeout(speak, 1000);
                } else {
                    // Les voix sont d√©j√† disponibles
                    speak();
                }
                break;

            case 'changerEtape':
                // √©viter les chgmt d'√©tape pdt que l'assistant parle
                if (speechQueueRef.current || isProcessing) {
                    console.log('Assistant en train de parler, changement d\'√©tape report√©');
                    return;
                }

                // v√©rif des limites de navigation
                if (etapeIndex < 0) {
                    gererVocal('parler', { texte: "Vous √™tes d√©j√† √† la premi√®re √©tape" });
                    return;
                }
                if (etapeIndex >= etapes.length) {
                    gererVocal('parler', { texte: "C'est la fin de la recette. Bon app√©tit !" });
                    return;
                }

                // maj de l'√©tat de l'√©tape actuelle
                etapeActuelleRef.current = etapeIndex; 
                setEtapeActuelle(etapeIndex);

                // notifier le composant parent du chgmt d'√©tape
                setTimeout(() => {
                    if (changeEtape) {
                        changeEtape(etapeIndex);
                    }
                }, 0);

                console.log(`Navigation vers l'√©tape ${etapeIndex + 1}/${etapes.length}`);

                // s'assurer que l'√©tat est √† jour
                setTimeout(() => {
                    const etapeTexte = etapes[etapeIndex]?.etape;
                    if (etapeTexte) {
                        let texteFinal = `√âtape ${etapeIndex + 1}: ${etapeTexte}`;

                        // msg de fin si derni√®re √©tape
                        if (etapeIndex === etapes.length - 1) {
                            texteFinal += ". C'est la fin de la recette. Bon app√©tit !";
                        }

                        // lancer la synth√®se vocale de l'√©tape
                        gererVocal('parler', {
                            texte: texteFinal,
                            isStep: true 
                        });
                    }
                }, 200);

                // maj affichage de derni√®re commande
                setLastCommand(`√âtape ${etapeIndex + 1}`);
                break;

            default:
                console.warn(`Action vocale inconnue: ${action}`);
        }
    }, [etapes, changeEtape, isProcessing]);

    // arr√™t complet assistant
    const stopAssistant = useCallback(() => {
        console.log('Arr√™t complet de l\'assistant vocal');

        if (recognitionRef.current) {
            recognitionRef.current.onend = null; // emp√™cher le red√©marrage automatique
            recognitionRef.current.stop();
            recognitionRef.current = null;
        }
        clearTimeout(restartTimeoutRef.current);

        // r√©initialiser tous les √©tats
        setEcoute(false);
        setActive(false);
        setIsProcessing(false);
        setIsReadingStep(false);
        speechQueueRef.current = false;
        utteranceRef.current = null;

        console.log('Assistant compl√®tement arr√™t√©');
    }, []);

    // traiter commandes vocales
    const traiterCommande = useCallback((transcript, confidence) => {
        // Ignorer commandes avec confiance trop faible
        if (confidence < CONFIDENCE_THRESHOLD) {
            console.log(`Commande ignor√©e (confiance ${confidence} < ${CONFIDENCE_THRESHOLD})`);
            return false;
        }

        const texte = transcript.toLowerCase().trim();
        console.log(`Traitement de la commande: "${texte}" (confiance: ${confidence})`);

        // nav par num
        // Recherche de patterns comme "√©tape 3" ou juste "3"
        const matchNumero = texte.match(/√©tape\s*(\d+)|^(\d+)$/);
        if (matchNumero) {
            const numero = parseInt(matchNumero[1] || matchNumero[2]);
            // v√©rif que le num existe
            if (numero >= 1 && numero <= etapes.length) {
                const targetIndex = numero - 1;
                gererVocal('changerEtape', { etapeIndex: targetIndex });
                return true;
            }
        }
        // r√©cup √©tape actuelle
        const currentEtape = etapeActuelleRef.current;

        // d√©finir les commandes
        const commandes = {
            '√©tape suivante': () => {
                const newIndex = Math.min(currentEtape + 1, etapes.length - 1);
                if (newIndex !== currentEtape) { // √©vite actions redondantes
                    gererVocal('changerEtape', { etapeIndex: newIndex });
                }
            },

            '√©tape pr√©c√©dente': () => {
                const newIndex = Math.max(currentEtape - 1, 0);
                if (newIndex !== currentEtape) {
                    gererVocal('changerEtape', { etapeIndex: newIndex });
                }
            },

            'r√©p√©ter': () => {
                gererVocal('changerEtape', { etapeIndex: currentEtape });
            },

            'ok chef': () => {
                gererVocal('changerEtape', { etapeIndex: 0 });
            },

            'd√©sactiver': () => {
                if (recognitionRef.current) {
                    recognitionRef.current.onend = null;
                    recognitionRef.current.stop();
                    recognitionRef.current = null;
                }
                clearTimeout(restartTimeoutRef.current);
                setEcoute(false);

                // la voix pour msg de d√©sactivation
                const voices = window.speechSynthesis.getVoices();
                const selectedVoice = voices.find(voice => voice.name === 'Am√©lie')
                    || voices.find(voice => voice.lang.startsWith('fr'))
                    || voices[0];

                // msg de confirmation de d√©sactivation
                const utterance = new SpeechSynthesisUtterance("Assistant d√©sactiv√©. Cliquez sur le bouton pour r√©activer.");
                utterance.lang = 'fr-FR';
                utterance.voice = selectedVoice;
                utterance.rate = 0.8;
                utterance.pitch = 1.0;
                utterance.volume = 1.0;

                // arr√™ter assistant une fois le msg termin√©
                utterance.onend = () => {
                    console.log('Message de d√©sactivation termin√©, arr√™t complet');
                    setActive(false);
                    setIsProcessing(false);
                    setIsReadingStep(false);
                    speechQueueRef.current = false;
                    utteranceRef.current = null;
                };

                utterance.onerror = () => {
                    console.log('Erreur lors de la synth√®se de d√©sactivation, arr√™t imm√©diat');
                    stopAssistant();
                };

                // arr√™ter toute synth√®se en cours et lancer le msg de d√©sactivation
                window.speechSynthesis.cancel();
                speechQueueRef.current = true;
                window.speechSynthesis.speak(utterance);
            }
        };

        // recherche commande exacte
        if (commandes[texte]) {
            commandes[texte]();
            return true;
        }

        // limiter √† 2 mots
        if (texte.split(" ").length <= 2) {
            for (const [motCle, action] of Object.entries(commandes)) {
                // Recherche de mots-cl√©s significatifs (longueur > 3)
                if (texte.includes(motCle) && motCle.length > 3) {
                    action();
                    return true;
                }
            }
        }
        return false;
    }, [etapes.length, stopAssistant, gererVocal]);

    // config reconnaissance vocale
    const setupRecognition = useCallback(() => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();

        Object.assign(recognition, {
            continuous: true,
            interimResults: false,
            lang: 'fr-FR',
            maxAlternatives: 1 
        });     

        // gestion events
        recognition.onstart = () => {
            console.log('Reconnaissance vocale d√©marr√©e');
            clearTimeout(restartTimeoutRef.current);
        };

        recognition.onresult = (event) => {
            // √©viter auto-√©coute
            if (isReadingStep || isProcessing) {
                console.log("Commande ignor√©e: assistant en train de parler");
                return;
            }

            // traiter nv r√©sultats
            for (let i = event.resultIndex; i < event.results.length; i++) {
                const result = event.results[i];

                // traiter que r√©sultats finaux
                if (result.isFinal) {
                    const [transcript, confidence] = [result[0].transcript, result[0].confidence];
                    const texte = transcript.toLowerCase().trim();

                    // filtrer txt trop longs
                    if (texte.length > 50) {
                        console.log("Texte ignor√©: trop long (auto-√©coute d√©tect√©e)");
                        return;
                    }
                    // filtrer txt trop courts
                    if (texte.length < 2) {
                        console.log("Texte ignor√©: trop court");
                        return;
                    }

                    console.log(`Commande d√©tect√©e: "${transcript}" (confiance: ${confidence}) - √âtape: ${etapeActuelleRef.current + 1}`);

                    const commandeReconnue = traiterCommande(transcript, confidence);

                    // logger les commandes non reconnues avec une bonne confiance
                    if (!commandeReconnue && confidence > 0.8 && texte.split(" ").length <= 3) {
                        console.warn("Commande non reconnue avec bonne confiance:", transcript);
                    }
                }
            }
        };

        recognition.onerror = (event) => {
            // ignorer "no-speech"
            if (event.error === 'no-speech') return;
            console.error('Erreur de reconnaissance vocale:', event.error);
        };

        recognition.onend = () => {
            console.log('Reconnaissance vocale arr√™t√©e');
            // red√©marrage automatique si assistant tjs actif
            if (active) {
                try {
                    recognition.start();
                    console.log("Red√©marrage automatique de la reconnaissance");
                } catch (error) {
                    console.error("Erreur lors du red√©marrage:", error);
                    restartTimeoutRef.current = setTimeout(() => {
                        try {
                            recognition.start();
                        } catch (retryError) {
                            console.error("√âchec du red√©marrage diff√©r√©:", retryError);
                        }
                    }, 1000);
                }
            }
        };

        return recognition;
    }, [traiterCommande, isReadingStep, isProcessing, active]);

    // micro
    const stopMicro = useCallback(() => {
        if (recognitionRef.current) {
            recognitionRef.current.onend = null; // Emp√™cher le red√©marrage automatique
            recognitionRef.current.stop();
            recognitionRef.current = null;
        }
        clearTimeout(restartTimeoutRef.current);
        setEcoute(false);
        console.log("Microphone d√©sactiv√© manuellement");
    }, []);

    // gestion √©coute
    const toggleEcoute = useCallback(() => {
        if (!ecoute) {
            // D√©marrer l'√©coute
            try {
                const recognition = setupRecognition();
                recognitionRef.current = recognition;
                recognition.start();
                setEcoute(true);
                console.log("√âcoute vocale activ√©e");
            } catch (error) {
                console.error('Erreur lors du d√©marrage de la reconnaissance:', error);
                setEcoute(false);
            }
        } else {
            stopMicro();
        }
    }, [ecoute, setupRecognition, stopMicro]);

    // test et activation assistant
    const testAssistant = useCallback(() => {
        // v√©rif support avant d'activer
        if (!supporte) {
            setShowFallback(true);
            return;
        }

        console.log("Activation de l'assistant vocal");
        setIsProcessing(true);

        gererVocal('parler', { texte: 'Bonjour, appuyez sur le bouton et dites "ok chef"' });

        setTimeout(() => {
            setActive(true);
            setIsProcessing(false);
            console.log("Assistant vocal pr√™t");
        }, 3000);
    }, [supporte, gererVocal]);

    // v√©rif support des APIs vocales au montage
    useEffect(() => {
        const checkSupport = () => {
            const isSupported = 'speechSynthesis' in window &&
                ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window);

            setSupporte(isSupported);
            setShowFallback(!isSupported);

            if (isSupported) {
                // chgmt des voix
                window.speechSynthesis.getVoices();
                console.log("Support vocal d√©tect√© et voix charg√©es");
            } else {
                console.warn("APIs vocales non support√©es par ce navigateur");
            }
        };

        checkSupport();

        // √©couter chgmt des voix
        if ('speechSynthesis' in window) {
            window.speechSynthesis.onvoiceschanged = checkSupport;
            // nettoyer listener au d√©montage
            return () => {
                window.speechSynthesis.onvoiceschanged = null;
            };
        }
    }, []);

    // synchronisation ref avec l'√©tat
    useEffect(() => {
        etapeActuelleRef.current = etapeActuelle;
        console.log(`√âtat synchronis√©: √©tape ${etapeActuelle + 1}/${etapes.length}`);
    }, [etapeActuelle, etapes.length]);

    useEffect(() => {
        return () => {
            console.log("Nettoyage du composant AssistantVocal");
            if (recognitionRef.current) {
                recognitionRef.current.stop();
            }
            if (utteranceRef.current) {
                window.speechSynthesis.cancel();
            }
            speechQueueRef.current = false;
            clearTimeout(restartTimeoutRef.current);
        };
    }, []);

    // txt du tooltip selon l'√©tat
    const getTooltipText = () => {
        if (isProcessing) return "Assistant en train de parler...";
        if (!active) return "Activer l'assistant vocal";
        if (!ecoute) return "Cliquez pour activer l'√©coute vocale";

        // commandes disponibles
        return `Commandes exactes:\n‚Ä¢ √©tape suivante \n‚Ä¢ √©tape pr√©c√©dente\n‚Ä¢ r√©p√©ter\n‚Ä¢ √©tape 1, 2, 3...\n‚Ä¢ d√©sactiver${lastCommand ? `\n\nDerni√®re: ${lastCommand}` : ''}`;
    };

    // CSS du btn selon l'√©tat
    const getButtonClasses = () => {
        const baseClasses = "w-14 h-14 md:w-16 md:h-16 rounded-full shadow-lg transform transition-all duration-300 flex items-center justify-center text-2xl font-bold hover:scale-110 hover:shadow-xl disabled:opacity-75 disabled:cursor-not-allowed";

        const stateClasses = ecoute
            ? "bg-red-500 text-white animate-pulse ring-4 ring-red-300"
            : active
                ? "bg-green-500 text-white hover:bg-green-600"
                : "bg-orange text-white hover:bg-brun";

        // Animation
        const processingClass = isProcessing ? "animate-spin" : "";

        return `${baseClasses} ${stateClasses} ${processingClass}`;
    };

    // icone btn selon l'√©tat
    const getButtonIcon = () => {
        return isProcessing ? '‚è≥' : ecoute ? 'üî¥' : active ? 'üé§' : '‚ñ∂Ô∏è';
    };

    const getStatusText = () => {
        return isProcessing ? "Parle..." : ecoute ? "√âcoute..." : "En attente";
    };

    // Ne pas afficher si pas de support et pas de fallback
    if (!supporte && !showFallback) return null;

    return (
        <>
            {/* btn principal flottant */}
            <div className="fixed bottom-6 right-6 z-50 font-quicksand">
                <div className="relative group">
                    <button
                        onClick={() => {
                            if (ecoute) {
                                stopMicro(); 
                            } else if (active) {
                                toggleEcoute();
                            } else {
                                testAssistant(); 
                            }
                        }}
                        disabled={isProcessing} // d√©sactiver pdt le traitement
                        className={getButtonClasses()}
                        title={getTooltipText()}
                        aria-label={getTooltipText()}
                    >
                        {getButtonIcon()}
                    </button>

                    {/* compteur √©tapes */}
                    {active && etapes.length > 0 && (
                        <div className="absolute -top-2 -right-2 bg-brun text-jaune text-xs font-bold rounded-full w-8 h-8 flex items-center justify-center shadow-lg transition-all duration-300">
                            {etapeActuelle + 1}/{etapes.length}
                        </div>
                    )}

                    {/* tooltip d√©taill√©*/}
                    <div className="absolute bottom-20 right-0 mb-2 px-3 py-2 bg-brun text-jaune text-xs md:text-sm rounded-lg shadow-lg whitespace-pre max-w-xs opacity-0 group-hover:opacity-100 transition-opacity duration-200 pointer-events-none">
                        {getTooltipText()}
                    </div>
                </div>

                {/* indicateur de statut */}
                {active && (
                    <div className="absolute -bottom-2 right-12 text-xs text-jaune bg-brun px-2 py-1 rounded shadow-sm border border-jaune">
                        {getStatusText()}
                    </div>
                )}
            </div>

            {/* interface de secours pour navigateurs non compatibles */}
            {showFallback && (
                <div className="fixed inset-0 bg-black bg-opacity-50 z-40 flex items-center justify-center">
                    <div className="bg-white rounded-lg p-6 m-4 max-w-sm">
                        <h3 className="text-lg font-bold mb-4">Assistant Vocal</h3>
                        <p className="text-sm text-gray-600 mb-4">
                            La reconnaissance vocale n&apos;est pas support√©e. Utilisez les contr√¥les manuels :
                        </p>

                        {/* btn de contr√¥le manuel */}
                        <div className="flex flex-wrap gap-2 mb-4">
                            {[
                                {
                                    text: "‚Üê Pr√©c√©dent",
                                    action: () => {
                                        const newIndex = Math.max(etapeActuelle - 1, 0);
                                        if (newIndex !== etapeActuelle) {
                                            setEtapeActuelle(newIndex);
                                            gererVocal('changerEtape', { etapeIndex: newIndex });
                                        }
                                    },
                                    disabled: etapeActuelle === 0
                                },
                                {
                                    text: "R√©p√©ter",
                                    action: () => gererVocal('changerEtape', { etapeIndex: etapeActuelle }),
                                    disabled: false
                                },
                                {
                                    text: "Suivant ‚Üí",
                                    action: () => {
                                        const newIndex = Math.min(etapeActuelle + 1, etapes.length - 1);
                                        if (newIndex !== etapeActuelle) {
                                            setEtapeActuelle(newIndex);
                                            gererVocal('changerEtape', { etapeIndex: newIndex });
                                        }
                                    },
                                    disabled: etapeActuelle === etapes.length - 1
                                }
                            ].map(({ text, action, disabled }, index) => (
                                <button
                                    key={index}
                                    className={`px-3 py-1 text-white rounded text-sm transition-colors ${disabled
                                        ? "bg-gray-300 cursor-not-allowed"
                                        : index === 1
                                            ? "bg-blue-500 hover:bg-blue-600"
                                            : "bg-gray-500 hover:bg-gray-600"
                                        }`}
                                    onClick={action}
                                    disabled={disabled}
                                    aria-label={text}
                                >
                                    {text}
                                </button>
                            ))}
                        </div>

                        <button
                            onClick={() => setShowFallback(false)}
                            className="w-full px-4 py-2 bg-red-500 text-white rounded hover:bg-red-600 transition-colors"
                            aria-label="Fermer l'interface de secours"
                        >
                            Fermer
                        </button>
                    </div>
                </div>
            )}
        </>
    );
}